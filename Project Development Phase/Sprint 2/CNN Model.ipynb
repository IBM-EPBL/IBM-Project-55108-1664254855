{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMDxzrc1E+8XPuATgX39jTE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fgkeLC4gPcC-"},"outputs":[],"source":["import numpy as np \n","import pandas as pd "]},{"cell_type":"code","source":["import os\n","for dirname, _, filenames in os.walk(r'C:\\Users\\HP\\Downloads\\archive (1)'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"],"metadata":{"id":"yC7ibzPJPii3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import os.path\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import load_img,img_to_array\n","print(tf.__version__)"],"metadata":{"id":"tfUDKLVcPlzB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dir = Path(r'C:\\Users\\HP\\Downloads\\archive (1)\\train')\n","train_filepaths = list(train_dir.glob(r'**/*.jpg'))\n","\n","test_dir = Path(r'C:\\Users\\HP\\Downloads\\archive (1)\\test')\n","test_filepaths = list(test_dir.glob(r'**/*.jpg')) \n","\n","val_dir = Path(r'C:\\Users\\HP\\Downloads\\archive (1)\\validation')\n","val_filepaths = list(test_dir.glob(r'**/*.jpg'))\n"],"metadata":{"id":"NwnrpEc5PnxW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def image_processing(filepath):\n","    \"\"\" Create a DataFrame with the filepath and the labels of the pictures\n","    \"\"\"\n","    \n","    labels = [str(filepath[i]).split(\"\\\\\")[-2]               for i in range(len(filepath))]\n","\n","    filepath = pd.Series(filepath, name='Filepath').astype(str)\n","    labels = pd.Series(labels, name='Label')\n","    df = pd.concat([filepath, labels], axis=1)\n","    df = df.sample(frac=1).reset_index(drop = True)\n","    return df\n"],"metadata":{"id":"mR48h-uHPqOd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = image_processing(train_filepaths)\n","test_df = image_processing(test_filepaths)\n","val_df = image_processing(val_filepaths)\n","train_df.head(5)"],"metadata":{"id":"P5X35wESPsoe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_unique = train_df.copy().drop_duplicates(subset=[\"Label\"]).reset_index()\n","fig, axes = plt.subplots(nrows=6, ncols=6, figsize=(8, 7),\n","                        subplot_kw={'xticks': [], 'yticks': []})\n","for i, ax in enumerate(axes.flat):\n","    ax.imshow(plt.imread(df_unique.Filepath[i]))\n","    ax.set_title(df_unique.Label[i], fontsize = 12)\n","plt.tight_layout(pad=0.5)\n","plt.show()"],"metadata":{"id":"FzK_ccJRPu_G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n","    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",")\n","\n","test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n","    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",")\n","\n"],"metadata":{"id":"AogvKp5-PxBa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_images = train_generator.flow_from_dataframe(\n","    dataframe=train_df,\n","    x_col='Filepath',\n","    y_col='Label',\n","    target_size=(224, 224),\n","    color_mode='rgb',\n","    class_mode='categorical',\n","    batch_size=32,\n","    shuffle=True,\n","    seed=0,\n","    rotation_range=30,\n","    zoom_range=0.15,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.15,\n","    horizontal_flip=True,\n","    fill_mode=\"nearest\"\n",")\n"],"metadata":{"id":"4esXwiuOQBf1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_images = train_generator.flow_from_dataframe(\n","    dataframe=val_df,\n","    x_col='Filepath',\n","    y_col='Label',\n","    target_size=(224, 224),\n","    color_mode='rgb',\n","    class_mode='categorical',\n","    batch_size=32,\n","    shuffle=True,\n","    seed=0,\n","    rotation_range=30,\n","    zoom_range=0.15,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.15,\n","    horizontal_flip=True,\n","    fill_mode=\"nearest\"\n",")\n"],"metadata":{"id":"F-EVA90IQEPs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_images = train_generator.flow_from_dataframe(\n","    dataframe=val_df,\n","    x_col='Filepath',\n","    y_col='Label',\n","    target_size=(224, 224),\n","    color_mode='rgb',\n","    class_mode='categorical',\n","    batch_size=32,\n","    shuffle=True,\n","    seed=0,\n","    rotation_range=30,\n","    zoom_range=0.15,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.15,\n","    horizontal_flip=True,\n","    fill_mode=\"nearest\"\n",")"],"metadata":{"id":"EivCJLvUQGP1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_images = test_generator.flow_from_dataframe(\n","    dataframe=test_df,\n","    x_col='Filepath',\n","    y_col='Label',\n","    target_size=(224, 224),\n","    color_mode='rgb',\n","    class_mode='categorical',\n","    batch_size=32,\n","    shuffle=False\n",")\n"],"metadata":{"id":"CUonC_HjQIcc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pretrained_model = tf.keras.applications.MobileNetV2(\n","    input_shape=(224, 224, 3),\n","    include_top=False,\n","    weights='imagenet',\n","    pooling='avg'\n",")\n","pretrained_model.trainable = False\n"],"metadata":{"id":"IOYOzffyQKr-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pretrained_model = tf.keras.applications.MobileNetV2(\n","    input_shape=(224, 224, 3),\n","    include_top=False,\n","    weights='imagenet',\n","    pooling='avg'\n",")\n","pretrained_model.trainable = False\n","\n","\n"],"metadata":{"id":"UxI5CyfgQgsA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = pretrained_model.input\n","\n","x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n","x = tf.keras.layers.Dense(128, activation='relu')(x)\n","\n","outputs = tf.keras.layers.Dense(36, activation='softmax')(x)\n","\n","model = tf.keras.Model(inputs=inputs, outputs=outputs)\n","\n","model.compile(\n","    optimizer='adam',\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","history = model.fit(\n","    train_images,\n","    validation_data=val_images,\n","    batch_size = 32,\n","    epochs=5,\n","    callbacks=[\n","        tf.keras.callbacks.EarlyStopping(\n","            monitor='val_loss',\n","            patience=2,\n","            restore_best_weights=True\n","        )\n","    ]\n",")"],"metadata":{"id":"bgCMCUUfQ34c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred = model.predict(test_images)\n","pred = np.argmax(pred,axis=1)\n","labels = (train_images.class_indices)\n","labels = dict((v,k) for k,v in labels.items())\n","pred1 = [labels[k] for k in pred]\n","pred1\n"],"metadata":{"id":"ElNLcjhWQhdp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.preprocessing import image\n","def output(location):\n","    img=load_img(location,target_size=(224,224,3))\n","    img=img_to_array(img)\n","    img=img/255\n","    img=np.expand_dims(img,[0])\n","    answer=model.predict(img)\n","    y_class = answer.argmax(axis=-1)\n","    y = \" \".join(str(x) for x in y_class)\n","    y = int(y)\n","    res = labels[y]\n","    return "],"metadata":{"id":"Ub3Cl6ItQlAX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img = output(r'C:\\Users\\HP\\Downloads\\archive (1)\\Image_10.jpg')\n","img"],"metadata":{"id":"QQ5rJhy9QmmK"},"execution_count":null,"outputs":[]}]}